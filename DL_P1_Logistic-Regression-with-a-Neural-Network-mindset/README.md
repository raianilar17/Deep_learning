# Build a logistic regression classifier to recognize cats

![](https://github.com/raianilar17/DL_P1/blob/master/Output_video1.gif)


I have taken a video and read each frame and made the prediction based on my trained  model. The best prediction result and its corresponding label are displayed on the frame itself.  

# Files 

1. [datasets](datasets): Training and Testing datasets available

2. [images](images): Testing images available.You can use your own image(Unseen image) and see the output of model

3. [output](output): output(videos) after model test.

4. [videos](videos): This is the sample video on which I have tested the code

5. [Python_Basics_With_Numpy.ipynb](Python_Basics_With_Numpy.ipynb): This notebook gives you a brief introduction to Python(Deep Learning). Even if you've used Python before, This will help familiarize you with functions that's need in deep learning.I have also added all the necessary comments as well.

6. [Logistic_Regression_with_a_Neural_Network_mindset.ipynb](Logistic_Regression_with_a_Neural_Network_mindset.ipynb): Here, I build a logistic regression classifier to recognize cats. This Notebook will step you through how to do this with a Neural Network mindset, and so will also hone your intuitions about deep learning.I have also added all the necessary comments as well.

# Command to run the code

run in jupyter notebook(The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain live code, equations, visualizations and narrative text. Uses include: data cleaning and transformation, numerical simulation, statistical modeling, data visualization, machine learning, and much more.)


For more detail please looks in notebook ([Python_Basics_With_Numpy.ipynb](Python_Basics_With_Numpy.ipynb) and [Logistic_Regression_with_a_Neural_Network_mindset.ipynb](Logistic_Regression_with_a_Neural_Network_mindset.ipynb)).


The notebook written in deep explanation with mathematical function.

# Future Work

Improve the model accuracy

Use different Hyperparameters(leraning_rate, iterations...)

Use different Regularization technique.

Use different Architecture.

Apply on differant application(field).
